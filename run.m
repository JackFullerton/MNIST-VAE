%Load Data using loadData function
[XTrain, numTrainImages,XTest,YTest]=loadData();

% GOAL 1: CONSTRUCT NETWORK
% -----------------------
% Create encoder and decoder. The encoder will take an image input and
% will output a compressed representation of vector size: latent_dim.
%
% The decoder takes the compressed representation, decodes it and recreates
% the original image.
%------------------------
% Define two vectors of size latent_dim: one of the means and one of the
% log of variances. Then use these vectors to create the distribution to
% sample from.
%

latentDim = 20;
imageSize = [28 28 1];

% Layer graphs for encoder and decoder
% encoder: Input,relu,conv,relu,fullyconnected
% -------------------
% Input layer will take in an image of size [28 28 1], set to not normalize
% data
%
% conv layer applies sliding convolutional filters to the input. The layer
% is passed in two numbers, representing number of filters and width/height
% of filter
%
% relu layer performs a threshold operation to each element of the input,
% where any value less than zero is set to zero.
%
% fully connected layer multiplies the input by a weight matrix and adds
% the bias vector. We pass in the output size as 2*latentDim

encoderLG = layerGraph([imageInputLayer(imageSize,'Name','input_encoder','Normalization','none')
    convolution2dLayer(3, 32, 'Padding','same', 'Stride', 2, 'Name', 'conv1')
    reluLayer('Name','relu1')
    convolution2dLayer(3, 64, 'Padding','same', 'Stride', 2, 'Name', 'conv2')
    reluLayer('Name','relu2')
    fullyConnectedLayer(2 * latentDim, 'Name', 'fc_encoder')]);

% decoder: Input, transposedConv, relu, transposedConv, relu,
% transposedConv, relu, transposedConv
decoderLG = layerGraph([
    imageInputLayer([1 1 latentDim],'Name','i','Normalization','none')
    transposedConv2dLayer(7, 64, 'Cropping', 'same', 'Stride', 7, 'Name', 'transpose1')
    reluLayer('Name','relu1')
    transposedConv2dLayer(3, 64, 'Cropping', 'same', 'Stride', 2, 'Name', 'transpose2')
    reluLayer('Name','relu2')
    transposedConv2dLayer(3, 32, 'Cropping', 'same', 'Stride', 2, 'Name', 'transpose3')
    reluLayer('Name','relu3')
    transposedConv2dLayer(3, 1, 'Cropping', 'same', 'Name', 'transpose4')
    ]);

% Convert the layer graphs to dlnetwork objects. Allows training with
% custom training loop. Note a requirement of this function is that there
% are no output layers and when training the network, calculate loss
% separately.
encoderNet = dlnetwork(encoderLG);
decoderNet = dlnetwork(decoderLG);

% At this stage we need to create a function that first samples the mean
% and variance vectors to create the final encoding to be passed to the
% decoder network.
%
% HOWEVER, because backpropagation through a random sampling operation is
% not possible, we must use the reparameterization trick. This trick moves
% the random sampling operation to an auxiliary variable epsilon, which is
% then shifted by the mean and scaled by the standard deviation.
% (Refer to VAE research paper for full explanation)
%
% The loss step passes the encoding generated by the previous sampling step
% through the decoder network and determines the loss, which is then used
% to compute the gradients. The loss in VAEs is called the ELBO loss.
% ELBO loss = reconstruction loss + KL loss.
%
% Reconstruction loss measures how close the decoder output is to the
% original input by using the mean-squared error(MSE)
% reconstruction loss = MSE(decoder output, original image)
%
% KL loss/divergence measures the difference between two probability
% distributions. Minimizing the KL divergence means that ensuring the
% learned means and variances are as close as possible to those of the
% targetted normal distribution.
% (Refer to VAE research paper for full explanation and equation) 
% -------------------------------------------

% TRAINING OPTIONS
% Train on auto: use GPU if available.
executionEnvironment = "auto";

%training options for the network
numEpochs = 50;
miniBatchSize = 512;
lr = 1e-3;
numIterations = floor(numTrainImages/miniBatchSize);
iteration = 0;

%Required for Adam optimizer
avgGradientsEncoder = [];
avgGradientsSquaredEncoder = [];
avgGradientsDecoder = [];
avgGradientsSquaredDecoder = [];

%
% TRAIN THE MODEL WITH CUSTOM TRAINING LOOP
%
for epoch = 1:numEpochs
    tic;
    for i = 1:numIterations
        iteration = iteration + 1;
        % For each iteration within epoch, obtain next mini-batch from
        % training set
        idx = (i-1)*miniBatchSize+1:i*miniBatchSize;
        XBatch = XTrain(:,:,:,idx);
        XBatch = dlarray(single(XBatch), 'SSCB');
        
        % Check if can use GPU here, if possible then convert to gpuArray
        if (executionEnvironment == "auto" && canUseGPU) || executionEnvironment == "gpu"
            XBatch = gpuArray(XBatch);           
        end 
            
        % Evaluate the model gradients using dlfeval and modelGradients
        % functions
        % dlfeval: https://uk.mathworks.com/help/deeplearning/ref/dlfeval.html
        % modelGradients: 
        % Update the learnables and average gradients for both networks
        % using adamupdate function
        % adamupdate: https://uk.mathworks.com/help/deeplearning/ref/adamupdate.html
        [infGrad, genGrad] = dlfeval(...
            @modelGradients, encoderNet, decoderNet, XBatch);
        
        [decoderNet.Learnables, avgGradientsDecoder, avgGradientsSquaredDecoder] = ...
            adamupdate(decoderNet.Learnables, ...
                genGrad, avgGradientsDecoder, avgGradientsSquaredDecoder, iteration, lr);
            
        [encoderNet.Learnables, avgGradientsEncoder, avgGradientsSquaredEncoder] = ...
            adamupdate(encoderNet.Learnables, ...
                infGrad, avgGradientsEncoder, avgGradientsSquaredEncoder, iteration, lr);
    end
    elapsedTime = toc; 
    
    % Finally, pass the test set images through autoencoder and calculate
    % loss for this epoch
    [z, zMean, zLogvar] = sampling(encoderNet, XTest);
    xPred = sigmoid(forward(decoderNet, z));
    elbo = ELBOloss(XTest, xPred, zMean, zLogvar);
    
    % Display epoch number, ELBO loss and the time taken
    disp("Epoch : "+epoch+" Test ELBO loss = "+gather(extractdata(elbo))+...
        ". Time taken for epoch = "+ elapsedTime + "s")    
end


% VISUALIZE GENERATIVE RESULTS 
generate(decoderNet, latentDim)


% Takes the encoder and decoder dlnetwork objects and a mini-batch of input
% data.
% Returns the gradients of the loss with respect to the learnable
% parameters in the networks
function [infGrad, genGrad] = modelGradients(encoderNet, decoderNet, x)
% obtain the encodings obtained from the sampling function.
[z, zMean, zLogvar] = sampling(encoderNet, x);

% obtain predicted dlarray using sigmoid function on the output of the
% decoder network and input data z
xPred = sigmoid(forward(decoderNet, z));

% Calculate the ELBO loss 
loss = ELBOloss(x, xPred, zMean, zLogvar);

% Calculate the gradients of the loss with respect to the learnable
% parameters of both encoder and decoder networks.
[genGrad, infGrad] = dlgradient(loss, decoderNet.Learnables, ...
    encoderNet.Learnables);
end

% sampling function obtains encodings from input images.
function [zSampled, zMean, zLogvar] = sampling(encoderNet, x)

% Passes mini-batch of data into encoder network and splits the output into
% a matrix of means and a matrix of variances.
compressed = forward(encoderNet, x);
d = size(compressed,1)/2;
zMean = compressed(1:d,:);
zLogvar = compressed(1+d:end,:);

% Perform the reparameterization trick
sz = size(zMean);
epsilon = randn(sz);
sigma = exp(.5 * zLogvar);
z = epsilon .* sigma + zMean;
z = reshape(z, [1,1,sz]);

% Convert encoding to dlarray object in SSCB format
zSampled = dlarray(z, 'SSCB');
end

% Function that takes the encodings of the means and variances returned by
% the sampling function to calculate the ELBO loss
function elbo = ELBOloss(x, xPred, zMean, zLogvar)

%Reconstruction loss
% !!!!!!!!!!!!!!
squares = 0.5*(xPred-x).^2;
reconstructionLoss  = sum(squares, [1,2,3]);

%KL divergence
KL = -.5 * sum(1 + zLogvar - zMean.^2 - exp(zLogvar), 1);

%Evidence lower bound loss
elbo = mean(reconstructionLoss + KL);
end
